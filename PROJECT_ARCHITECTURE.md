# ğŸ›¡ï¸ PoisonProof AI â€” Complete Project Documentation

> **Enterprise-grade AI Security Platform for Data Poisoning Detection, Anomaly Analysis, and ML Model Integrity Verification**

---

## ğŸ“‹ Table of Contents

1. [Project Overview](#1-project-overview)
2. [Architecture Overview](#2-architecture-overview)
3. [Directory Structure](#3-directory-structure)
4. [Core Components](#4-core-components)
5. [Data Flow & Request Lifecycle](#5-data-flow--request-lifecycle)
6. [Detection Engine](#6-detection-engine)
7. [Machine Learning Platform](#7-machine-learning-platform)
8. [Security Features](#8-security-features)
9. [Frontend & UI Components](#9-frontend--ui-components)
10. [API Reference](#10-api-reference)
11. [Configuration](#11-configuration)
12. [Database & Storage](#12-database--storage)
13. [Deployment Guide](#13-deployment-guide)
14. [Testing](#14-testing)
15. [Technology Stack](#15-technology-stack)

---

## 1. Project Overview

### What is PoisonProof AI?

PoisonProof AI is a comprehensive security platform designed to detect and mitigate **data poisoning attacks** on machine learning datasets. It provides:

- **Threat Detection**: Scans CSV datasets for 40+ injection patterns (SQL, XSS, Command Injection, etc.)
- **Statistical Anomaly Detection**: Uses robust statistical methods (MAD, IQR) to identify outliers
- **Image Forensics**: Analyzes images for manipulation, steganography, and metadata tampering
- **ML Model Training**: Live training console with real-time progress streaming
- **Model Integrity**: SHA-256 cryptographic verification for trained models
- **Data Cleaning**: Automated and manual cleaning workflows

### Problem Statement

When training AI/ML models, poisoned training data can lead to:
- **Backdoor Attacks**: Models behave normally but fail on specific trigger inputs
- **Model Degradation**: Gradual reduction in model accuracy
- **Security Vulnerabilities**: Injection payloads embedded in data
- **Data Integrity Issues**: Statistical outliers skewing model behavior

### Solution

PoisonProof AI provides a multi-layered defense:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PoisonProof AI                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 1: Injection Detection (40+ patterns)                        â”‚
â”‚  Layer 2: Statistical Outlier Analysis (MAD/IQR)                    â”‚
â”‚  Layer 3: Image Forensics (ELA, Entropy, EXIF)                      â”‚
â”‚  Layer 4: Data Cleaning (Auto/Manual)                               â”‚
â”‚  Layer 5: Model Training with Integrity Verification                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Architecture Overview

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              CLIENT (Browser)                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Upload    â”‚  â”‚   Results   â”‚  â”‚   Train     â”‚  â”‚   Models    â”‚        â”‚
â”‚  â”‚   Page      â”‚  â”‚   View      â”‚  â”‚   Console   â”‚  â”‚  Dashboard  â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                â”‚                â”‚
          â–¼                â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           FLASK APPLICATION                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                         Route Handlers (app.py)                         â”‚ â”‚
â”‚  â”‚   /scan  â”‚  /clean  â”‚  /train  â”‚  /models  â”‚  /api/*                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                           UTILS LAYER                                  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚  â”‚
â”‚  â”‚  â”‚ detection.pyâ”‚  â”‚ security.py â”‚  â”‚  cleaner.py â”‚                    â”‚  â”‚
â”‚  â”‚  â”‚ - CSV Scan  â”‚  â”‚ - Hash      â”‚  â”‚ - Auto Cleanâ”‚                    â”‚  â”‚
â”‚  â”‚  â”‚ - Image     â”‚  â”‚ - Patterns  â”‚  â”‚ - Manual    â”‚                    â”‚  â”‚
â”‚  â”‚  â”‚   Analysis  â”‚  â”‚ - Audit Log â”‚  â”‚   Clean     â”‚                    â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                    â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                        ML TRAINING (model_trainer.py)                  â”‚  â”‚
â”‚  â”‚   - Streaming Training (SSE)                                          â”‚  â”‚
â”‚  â”‚   - Multiple Algorithms (LogReg, RF, SVM)                             â”‚  â”‚
â”‚  â”‚   - SHA-256 Model Hashing                                             â”‚  â”‚
â”‚  â”‚   - Metrics Calculation                                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                                    â”‚
          â–¼                                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      FILE STORAGE         â”‚              â”‚          MODEL STORAGE            â”‚
â”‚  uploads/                 â”‚              â”‚  trained_models/                  â”‚
â”‚   â”œâ”€â”€ dataset.csv         â”‚              â”‚   â”œâ”€â”€ LogisticRegression_*.pkl   â”‚
â”‚   â””â”€â”€ *_cleaned.csv       â”‚              â”‚   â”œâ”€â”€ RandomForest_*.pkl         â”‚
â”‚                           â”‚              â”‚   â””â”€â”€ model_hashes.json          â”‚
â”‚  logs/                    â”‚              â”‚                                   â”‚
â”‚   â””â”€â”€ audit.json          â”‚              â”‚                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Interaction Flow

```
User Upload â†’ Route Handler â†’ Detection Engine â†’ Anomaly Report
                                    â”‚
                                    â–¼
                            Cleaning Pipeline
                                    â”‚
                                    â–¼
                            ML Training (SSE)
                                    â”‚
                                    â–¼
                        Model Registry + Hash Verification
```

---

## 3. Directory Structure

```
PoisonProof-AI/
â”‚
â”œâ”€â”€ ğŸ“„ app.py                    # Main Flask application (668 lines)
â”œâ”€â”€ ğŸ“„ config.py                 # Configuration classes (Dev/Prod/Test)
â”œâ”€â”€ ğŸ“„ run.py                    # Application entry point
â”œâ”€â”€ ğŸ“„ model_trainer.py          # ML training with SSE streaming
â”œâ”€â”€ ğŸ“„ generate_training_dataset.py  # Dataset generator utility
â”œâ”€â”€ ğŸ“„ gen.py                    # Additional generation utilities
â”‚
â”œâ”€â”€ ğŸ“ utils/                    # Core utility modules
â”‚   â”œâ”€â”€ detection.py             # Anomaly detection engine
â”‚   â”œâ”€â”€ security.py              # Security utilities & patterns
â”‚   â””â”€â”€ cleaner.py               # Data cleaning functions
â”‚
â”œâ”€â”€ ğŸ“ templates/                # Jinja2 HTML templates
â”‚   â”œâ”€â”€ base.html                # Base template with navbar/footer
â”‚   â”œâ”€â”€ index.html               # Landing page (hero + features)
â”‚   â”œâ”€â”€ upload.html              # File upload interface
â”‚   â”œâ”€â”€ results.html             # Scan results display
â”‚   â”œâ”€â”€ review.html              # Manual anomaly review
â”‚   â”œâ”€â”€ clean.html               # Cleaning report
â”‚   â”œâ”€â”€ train.html               # Training configuration
â”‚   â”œâ”€â”€ train_live.html          # Live training console (SSE)
â”‚   â””â”€â”€ models.html              # Model comparison dashboard
â”‚
â”œâ”€â”€ ğŸ“ static/                   # Static assets
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css            # Cyber-themed CSS (200+ custom rules)
â”‚   â””â”€â”€ js/
â”‚       â”œâ”€â”€ main.js              # Core JavaScript utilities
â”‚       â”œâ”€â”€ cyber_effects.js     # Matrix rain animation
â”‚       â””â”€â”€ train_console.js     # Training console logic
â”‚
â”œâ”€â”€ ğŸ“ uploads/                  # Uploaded files (auto-cleaned after 15min)
â”‚   â””â”€â”€ *.csv
â”‚
â”œâ”€â”€ ğŸ“ trained_models/           # Trained model storage
â”‚   â”œâ”€â”€ *.pkl                    # Serialized scikit-learn models
â”‚   â””â”€â”€ model_hashes.json        # Model registry with hashes
â”‚
â”œâ”€â”€ ğŸ“ logs/                     # Audit logs
â”‚   â””â”€â”€ audit.json               # JSON audit trail
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt          # Python dependencies
â”œâ”€â”€ ğŸ“„ pyproject.toml            # Project metadata
â”œâ”€â”€ ğŸ“„ training_dataset.csv      # Pre-built 800-row training dataset
â”œâ”€â”€ ğŸ“„ sample_data.csv           # Sample data for testing
â”œâ”€â”€ ğŸ“„ test_app.py               # Unit tests
â”‚
â”œâ”€â”€ ğŸ“„ README.md                 # Quick start guide
â”œâ”€â”€ ğŸ“„ FEATURES.md               # Feature implementation details
â”œâ”€â”€ ğŸ“„ DATASET_GUIDE.md          # Dataset documentation
â”œâ”€â”€ ğŸ“„ DATASET_SUMMARY.md        # Dataset statistics
â”œâ”€â”€ ğŸ“„ TRAINING_QUICKSTART.md    # Training guide
â””â”€â”€ ğŸ“„ LICENSE                   # License file
```

---

## 4. Core Components

### 4.1 Flask Application (`app.py`)

The main application file implementing the Flask web server using the **Application Factory Pattern**.

```python
def create_app(config_name=None):
    """Application factory pattern"""
    app = Flask(__name__)
    config_name = config_name or os.environ.get('FLASK_ENV', 'development')
    app.config.from_object(config[config_name])
    os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
    register_routes(app)
    return app
```

**Key Features:**
- Factory pattern for testability
- Environment-based configuration
- Session management with UUID tracking
- Comprehensive route registration

### 4.2 Route Structure

| Route | Method | Function | Description |
|-------|--------|----------|-------------|
| `/` | GET | `index()` | Landing page |
| `/upload` | GET | `upload_page()` | File upload form |
| `/scan` | POST | `scan_file()` | Process uploaded file |
| `/clean/<filename>` | GET/POST | `clean_file()` | Manual cleaning |
| `/clean/auto/<filename>` | GET | `auto_clean_file()` | Auto cleaning |
| `/train` | GET/POST | `train_model()` | Training page |
| `/train/live/<job_id>` | GET | `train_live()` | Live console |
| `/train/stream/<job_id>` | GET | `train_stream()` | SSE stream |
| `/models` | GET | `models_dashboard()` | Model comparison |
| `/models/download/<file>` | GET | `download_model()` | Download model |
| `/models/delete/<file>` | POST | `delete_model()` | Delete model |

### 4.3 Detection Engine (`utils/detection.py`)

The detection engine provides comprehensive anomaly detection:

```python
def detect_csv_anomalies(df: pd.DataFrame, max_findings: int = 50) -> List[Dict]:
    """
    Multi-layer detection:
    1. Text-based injection signature scanning
    2. Robust Z-score outlier detection (MAD)
    3. IQR-based boundary detection
    """
```

**Detection Methods:**

| Method | Description | Use Case |
|--------|-------------|----------|
| `robust_z_score()` | MAD-based z-scores | Robust to outliers |
| `iqr_bounds()` | Interquartile range fences | Statistical boundaries |
| `_check_exif_anomalies()` | EXIF metadata analysis | Image tampering |
| `_check_entropy()` | Statistical entropy | Steganography detection |
| `analyze_image()` | Full image forensics | ELA, blur, dynamic range |

### 4.4 Security Module (`utils/security.py`)

Handles security-related operations:

```python
# 40+ injection patterns organized by attack type
INJECTION_PATTERNS = [
    # XSS (Cross-Site Scripting)
    r"<script[\s>]",
    r"onerror\s*=",
    r"javascript:",
    
    # SQL Injection
    r"drop\s+table",
    r"union\s+select",
    r"'\s*or\s*'1'\s*=\s*'1",
    
    # Command Injection
    r";\s*rm\s+-rf",
    r"\$\(.*\)",
    r"`.*`",
    
    # Path Traversal
    r"\.\./",
    r"/etc/passwd",
    
    # NoSQL Injection
    r"\$ne\s*:",
    r"\$where\s*:",
    
    # LDAP Injection
    r"\*\)\s*\(",
]
```

**Security Functions:**

| Function | Purpose |
|----------|---------|
| `hash_file(path)` | SHA-256 file hashing |
| `hash_bytes(data)` | SHA-256 bytes hashing |
| `allowed_file(filename)` | Extension validation |
| `scan_payload_signatures(text)` | Injection pattern matching |
| `schedule_cleanup(path, delay)` | Timed file deletion |
| `log_audit_event(event)` | Audit trail logging |

### 4.5 Data Cleaner (`utils/cleaner.py`)

Provides data cleaning capabilities:

```python
def auto_clean(df: pd.DataFrame, anomalies: List[Dict]) -> Tuple[pd.DataFrame, Dict]:
    """Drop rows with High severity anomalies."""
    
def manual_clean(df: pd.DataFrame, rows_to_drop: List[int]) -> Tuple[pd.DataFrame, Dict]:
    """Drop user-selected rows."""
```

### 4.6 Model Trainer (`model_trainer.py`)

ML training with real-time streaming:

```python
def train_model_streaming(df, model_type='LogisticRegression', target=None):
    """Generator yielding training progress for SSE."""
    yield {'status': 'Loading dataset...', 'progress': 10}
    # ... training steps
    yield {'metrics': metrics, 'progress': 80}
    yield {'hash': model_hash}
    yield {'status': 'Training complete.', 'progress': 100}
```

**Supported Models:**

| Model | Class | Use Case |
|-------|-------|----------|
| Logistic Regression | `LogisticRegression` | Binary classification baseline |
| Random Forest | `RandomForestClassifier` | Ensemble with feature importance |
| Support Vector Machine | `SVC` | Non-linear decision boundaries |

---

## 5. Data Flow & Request Lifecycle

### 5.1 File Upload & Scan Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User       â”‚
â”‚ Uploads CSV  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. POST /scan                                                â”‚
â”‚     - Validate file extension                                 â”‚
â”‚     - secure_filename() sanitization                          â”‚
â”‚     - Save to uploads/                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Detection Engine                                          â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚     â”‚ a) Text Column Scan                                  â”‚  â”‚
â”‚     â”‚    - For each object column                          â”‚  â”‚
â”‚     â”‚    - scan_payload_signatures() on each cell          â”‚  â”‚
â”‚     â”‚    - Flag injection patterns                         â”‚  â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚     â”‚ b) Numeric Column Analysis                           â”‚  â”‚
â”‚     â”‚    - robust_z_score() per column                     â”‚  â”‚
â”‚     â”‚    - iqr_bounds() per column                         â”‚  â”‚
â”‚     â”‚    - Flag values exceeding thresholds                â”‚  â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚     â”‚ c) Row Score Aggregation                             â”‚  â”‚
â”‚     â”‚    - Sum flagged column scores per row               â”‚  â”‚
â”‚     â”‚    - Rank rows by total anomaly score                â”‚  â”‚
â”‚     â”‚    - Return top N findings                           â”‚  â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Generate Visualization                                    â”‚
â”‚     - Plotly pie chart (severity distribution)               â”‚
â”‚     - JSON-encoded for frontend                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Store Session Data                                        â”‚
â”‚     - File path, filename, SHA-256 hash                      â”‚
â”‚     - Schedule cleanup (15 min)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Render results.html                                       â”‚
â”‚     - Anomaly table with severity badges                     â”‚
â”‚     - Interactive chart                                      â”‚
â”‚     - Links to clean/train                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Training Flow (SSE)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Start Train â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  POST /train                                             â”‚
â”‚  - Generate job_id (UUID)                               â”‚
â”‚  - Store in session: path, model_type, status           â”‚
â”‚  - Redirect to /train/live/<job_id>                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GET /train/live/<job_id>                               â”‚
â”‚  - Render train_live.html                               â”‚
â”‚  - JavaScript connects to EventSource                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GET /train/stream/<job_id>  (SSE Connection)           â”‚
â”‚                                                          â”‚
â”‚  Generator yields events:                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Event 1: {"status": "Loading dataset...",         â”‚  â”‚
â”‚  â”‚           "progress": 10}                         â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Event 2: {"status": "Target column: is_anomaly",  â”‚  â”‚
â”‚  â”‚           "progress": 20}                         â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Event 3: {"status": "Splitting data (75/25)...",  â”‚  â”‚
â”‚  â”‚           "progress": 30}                         â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Event 4: {"status": "Training RandomForest...",   â”‚  â”‚
â”‚  â”‚           "progress": 40}                         â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Event 5: {"status": "Training complete.",         â”‚  â”‚
â”‚  â”‚           "progress": 70}                         â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Event 6: {"metrics": {"accuracy": 0.85, ...},     â”‚  â”‚
â”‚  â”‚           "progress": 80}                         â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Event 7: {"hash": "abc123...",                    â”‚  â”‚
â”‚  â”‚           "progress": 95}                         â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Event 8: {"message": "complete"}                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model Saved:                                            â”‚
â”‚  - trained_models/RandomForestClassifier_<ts>.pkl       â”‚
â”‚  - model_hashes.json updated with:                      â”‚
â”‚    {                                                    â”‚
â”‚      "model_name": "RandomForestClassifier_1234.pkl",  â”‚
â”‚      "hash": "sha256...",                              â”‚
â”‚      "trained_at": "2026-01-07T10:30:00Z",             â”‚
â”‚      "metrics": {...},                                  â”‚
â”‚      "model_type": "RandomForestClassifier"            â”‚
â”‚    }                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. Detection Engine

### 6.1 Injection Pattern Categories

| Category | Patterns | Severity | Examples |
|----------|----------|----------|----------|
| **XSS** | 8 patterns | High | `<script>`, `onerror=`, `javascript:`, `<iframe>` |
| **SQL Injection** | 10 patterns | High | `DROP TABLE`, `UNION SELECT`, `'OR'1'='1` |
| **Command Injection** | 7 patterns | High | `; rm -rf`, `$(...)`, backticks |
| **Path Traversal** | 4 patterns | Medium | `../`, `..\\`, `/etc/passwd` |
| **NoSQL Injection** | 3 patterns | High | `$ne:`, `$gt:`, `$where:` |
| **LDAP Injection** | 3 patterns | Medium | `*)(`, `(|`, `)(...)=*` |

### 6.2 Statistical Detection Methods

#### Robust Z-Score (MAD-based)

```python
def robust_z_score(series: pd.Series) -> pd.Series:
    """
    Formula: Z = 0.6745 * (x - median) / MAD
    
    - Uses Median Absolute Deviation (MAD) instead of std
    - Robust to outliers (unlike standard z-score)
    - 0.6745 normalizes MAD to be consistent with std for normal distributions
    """
    med = np.nanmedian(s)
    mad = np.nanmedian(np.abs(s - med))
    return 0.6745 * (s - med) / mad
```

**Threshold:** |z| > 3.5 â†’ Flagged as outlier

#### IQR Bounds

```python
def iqr_bounds(series: pd.Series):
    """
    Classic Tukey fences:
    Lower = Q1 - 1.5 * IQR
    Upper = Q3 + 1.5 * IQR
    """
    q1 = np.nanpercentile(s, 25)
    q3 = np.nanpercentile(s, 75)
    iqr = q3 - q1
    return q1 - 1.5 * iqr, q3 + 1.5 * iqr
```

### 6.3 Image Forensics

#### Error Level Analysis (ELA)

```
Original Image â†’ JPEG Compress (90%) â†’ Compare Difference
                                             â”‚
                                             â–¼
                                    High difference in region
                                    = Possible manipulation
```

| ELA Score | Interpretation |
|-----------|---------------|
| < 12.0 | Normal |
| 12.0 - 20.0 | Medium suspicion |
| > 20.0 | High suspicion |

#### Entropy Analysis

```python
def _check_entropy(gray: np.ndarray):
    """
    Shannon entropy of pixel histogram
    
    Normal images: 6.5 - 7.5 bits/pixel
    High entropy (>7.8): Hidden data (steganography)
    Low entropy (<5.5): Synthetic/low-complexity
    """
```

#### EXIF Metadata Checks

- **Software Tags**: Detects Photoshop, GIMP, Paint.NET, Affinity
- **Camera Tags**: Flags missing Make/Model (possible stripped metadata)

---

## 7. Machine Learning Platform

### 7.1 Training Pipeline

```python
def _prepare_xy(df, target):
    """
    1. If target not specified, use last column
    2. Extract numeric features only
    3. Fill NaN with median
    4. Factorize categorical targets
    """
    
def train_model_streaming(df, model_type, target):
    """
    1. Prepare X, y
    2. Train/test split (75/25)
    3. Train model with progress events
    4. Calculate metrics
    5. Save model (.pkl)
    6. Generate SHA-256 hash
    7. Update registry
    """
```

### 7.2 Model Registry (`model_hashes.json`)

```json
[
  {
    "model_name": "LogisticRegression_1704614400.pkl",
    "hash": "a3f2b1c4d5e6f7890abcdef1234567890abcdef1234567890abcdef12345678",
    "trained_at": "2026-01-07T10:00:00+00:00",
    "metrics": {
      "accuracy": 0.8550,
      "precision": 0.8234,
      "recall": 0.7891
    },
    "model_type": "LogisticRegression"
  }
]
```

### 7.3 Model Verification

```python
# On dashboard load:
file_path = os.path.join(TRAINED_DIR, model_name)
if os.path.exists(file_path):
    current_hash = hash_file(file_path)
    verified = (current_hash == stored_hash)  # âœ“ or âš ï¸
```

### 7.4 Metrics Calculated

| Metric | Formula | Purpose |
|--------|---------|---------|
| **Accuracy** | (TP + TN) / Total | Overall correctness |
| **Precision** | TP / (TP + FP) | Positive prediction accuracy |
| **Recall** | TP / (TP + FN) | True positive capture rate |

---

## 8. Security Features

### 8.1 File Security

| Feature | Implementation |
|---------|---------------|
| **File Extension Validation** | Whitelist: `csv, png, jpg, jpeg, gif, bmp` |
| **Filename Sanitization** | `werkzeug.utils.secure_filename()` |
| **Size Limit** | 16MB max (`MAX_CONTENT_LENGTH`) |
| **Auto-Cleanup** | Files deleted after 15 minutes |

### 8.2 Cryptographic Verification

```python
def hash_file(path: str) -> str:
    """SHA-256 hash with 8KB block reading for large files"""
    sha256 = hashlib.sha256()
    with open(path, 'rb') as f:
        for block in iter(lambda: f.read(8192), b''):
            sha256.update(block)
    return sha256.hexdigest()
```

### 8.3 Session Management

```python
@app.before_request
def _ensure_session():
    session.permanent = True  # 1-hour lifetime
    if 'session_id' not in session:
        session['session_id'] = uuid.uuid4().hex[:8]
```

### 8.4 Audit Logging

```python
def log_audit_event(event: Dict):
    """Append to logs/audit.json with timestamp"""
    event.setdefault('timestamp', datetime.now(timezone.utc).isoformat())
    data.append(event)
```

### 8.5 Production Security Config

```python
class ProductionConfig(Config):
    SECRET_KEY = os.environ.get('SECRET_KEY') or os.urandom(32)
    SESSION_COOKIE_SECURE = True     # HTTPS only
    SESSION_COOKIE_HTTPONLY = True   # No JavaScript access
    SESSION_COOKIE_SAMESITE = 'Lax'  # CSRF protection
```

---

## 9. Frontend & UI Components

### 9.1 Template Inheritance

```
base.html
â”œâ”€â”€ index.html      (Hero + Features)
â”œâ”€â”€ upload.html     (File upload form)
â”œâ”€â”€ results.html    (Scan results + chart)
â”œâ”€â”€ review.html     (Manual anomaly review)
â”œâ”€â”€ clean.html      (Cleaning report)
â”œâ”€â”€ train.html      (Training config)
â”œâ”€â”€ train_live.html (SSE console)
â””â”€â”€ models.html     (Dashboard)
```

### 9.2 Cyber Theme CSS

```css
:root {
    --accent-green: #00ff7f;
    --accent-cyan: #00ffff;
    --border-color: rgba(0, 255, 127, 0.3);
    --border-glow: rgba(0, 255, 127, 0.5);
    --bg-dark: #0a0f14;
    --text-light: #b0b0b0;
}
```

**Visual Effects:**
- Matrix rain canvas animation
- Neon glow text shadows
- Scan line gradients
- Threat meter color gradients
- Pulsing status badges

### 9.3 JavaScript Components

| File | Purpose |
|------|---------|
| `main.js` | Core utilities, navigation, alerts |
| `cyber_effects.js` | Matrix rain animation |
| `train_console.js` | SSE connection, progress updates |

### 9.4 External Libraries

- **Bootstrap 5.3.2**: Responsive grid, components
- **Bootstrap Icons 1.11.1**: Icon fonts
- **Plotly.js**: Interactive charts
- **Google Fonts**: Orbitron, JetBrains Mono

---

## 10. API Reference

### 10.1 RESTful Endpoints

#### `GET /api/audit-log`

Returns complete audit log.

**Response:**
```json
{
  "success": true,
  "count": 15,
  "logs": [
    {
      "timestamp": "2026-01-07T10:00:00+00:00",
      "event": "file_upload",
      "filename": "dataset.csv",
      "session_id": "abc123"
    }
  ]
}
```

#### `GET /api/audit-log/export`

Downloads audit log as CSV file.

#### `GET /api/models`

Returns all trained models.

**Response:**
```json
{
  "success": true,
  "count": 3,
  "models": [
    {
      "model_name": "LogisticRegression_1234.pkl",
      "hash": "abc123...",
      "metrics": {
        "accuracy": 0.85,
        "precision": 0.82,
        "recall": 0.79
      },
      "trained_at": "2026-01-07T10:00:00Z"
    }
  ]
}
```

#### `POST /api/verify/<file_hash>`

Verify file integrity against expected hash.

**Request:**
```
Content-Type: multipart/form-data
Body: file=@model.pkl
```

**Response:**
```json
{
  "success": true,
  "match": true,
  "expected": "abc123...",
  "actual": "abc123...",
  "status": "verified"
}
```

---

## 11. Configuration

### 11.1 Configuration Classes

```python
class Config:
    SECRET_KEY = os.environ.get('SECRET_KEY') or 'dev-secret-key'
    UPLOAD_FOLDER = os.path.join(os.getcwd(), 'uploads')
    MAX_CONTENT_LENGTH = 16 * 1024 * 1024  # 16MB
    ALLOWED_EXTENSIONS = {'csv', 'png', 'jpg', 'jpeg', 'gif', 'bmp'}
    PERMANENT_SESSION_LIFETIME = timedelta(hours=1)

class DevelopmentConfig(Config):
    DEBUG = True
    ENV = 'development'

class ProductionConfig(Config):
    DEBUG = False
    SESSION_COOKIE_SECURE = True
    SESSION_COOKIE_HTTPONLY = True
```

### 11.2 Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `FLASK_ENV` | `development` | Environment mode |
| `SECRET_KEY` | random | Session encryption key |
| `PORT` | `5000` | Server port (production) |

---

## 12. Database & Storage

### 12.1 File-Based Storage

PoisonProof AI uses **file-based storage** (no external database required):

| Storage | Path | Format | Purpose |
|---------|------|--------|---------|
| Uploads | `uploads/` | CSV/Images | Temporary file storage |
| Models | `trained_models/*.pkl` | Pickle | Trained sklearn models |
| Registry | `trained_models/model_hashes.json` | JSON | Model metadata |
| Audit | `logs/audit.json` | JSON | Audit trail |

### 12.2 Model Hashes Schema

```json
{
  "model_name": "string",
  "hash": "string (SHA-256)",
  "trained_at": "string (ISO 8601)",
  "metrics": {
    "accuracy": "float",
    "precision": "float",
    "recall": "float"
  },
  "model_type": "string"
}
```

---

## 13. Deployment Guide

### 13.1 Development Setup

```powershell
# 1. Clone repository
git clone https://github.com/joedanields/PoisonProof-AI.git
cd PoisonProof-AI

# 2. Create virtual environment
python -m pip install uv
uv venv .venv
.\.venv\Scripts\Activate.ps1

# 3. Install dependencies
uv pip install -r requirements.txt

# 4. Run development server
python run.py
```

### 13.2 Production Deployment

```bash
# Set environment
export FLASK_ENV=production
export SECRET_KEY=$(openssl rand -hex 32)

# Run with Gunicorn (Linux)
gunicorn -w 4 -b 0.0.0.0:5000 "app:create_app('production')"

# Or with Waitress (Windows)
waitress-serve --host=0.0.0.0 --port=5000 app:app
```

### 13.3 Docker Deployment

```dockerfile
FROM python:3.12-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
ENV FLASK_ENV=production
EXPOSE 5000
CMD ["python", "run.py"]
```

---

## 14. Testing

### 14.1 Test Structure (`test_app.py`)

```python
def test_app_creation():
    """Test Flask app factory"""
    app = create_app('testing')
    assert app is not None

def test_file_hash():
    """Test SHA-256 hashing"""
    hash_result = calculate_file_hash(temp_path)
    assert len(hash_result) == 64

def test_csv_anomaly_detection():
    """Test detection engine on sample data"""
```

### 14.2 Running Tests

```bash
python test_app.py

# Or with pytest
pytest test_app.py -v
```

---

## 15. Technology Stack

### 15.1 Backend

| Technology | Version | Purpose |
|------------|---------|---------|
| Python | 3.10+ | Runtime |
| Flask | 2.3.3 | Web framework |
| Werkzeug | 2.3.7 | WSGI utilities |
| pandas | 1.5.x | Data manipulation |
| NumPy | 1.21-1.24 | Numerical computing |
| scikit-learn | - | ML models |
| Pillow | 10.0.1 | Image processing |
| Plotly | 5.17.0 | Charting |
| joblib | - | Model serialization |

### 15.2 Frontend

| Technology | Version | Purpose |
|------------|---------|---------|
| Bootstrap | 5.3.2 | CSS framework |
| Bootstrap Icons | 1.11.1 | Icons |
| Plotly.js | (bundled) | Charts |
| Jinja2 | (Flask) | Templating |
| Custom CSS | - | Cyber theme |

### 15.3 Standards & Protocols

- **HTTP**: RESTful API design
- **SSE**: Server-Sent Events for real-time streaming
- **JSON**: Data interchange format
- **SHA-256**: Cryptographic hashing
- **Pickle**: Model serialization

---

## ğŸ“Š Training Dataset

The pre-built `training_dataset.csv` contains:

- **800 rows** total
- **603 normal samples** (75.4%)
- **197 anomalous samples** (24.6%)

**Anomaly Types:**
- SQL Injection payloads
- XSS attack patterns
- Command injection attempts
- Path traversal strings
- Statistical outliers (salary, age extremes)
- Invalid data (negative values, extreme ranges)

---

## ğŸ”— Quick Links

| Resource | Description |
|----------|-------------|
| [README.md](README.md) | Quick start guide |
| [FEATURES.md](FEATURES.md) | Feature implementation details |
| [TRAINING_QUICKSTART.md](TRAINING_QUICKSTART.md) | ML training guide |
| [DATASET_GUIDE.md](DATASET_GUIDE.md) | Dataset documentation |

---

## ğŸ“ License

This project is licensed under the terms specified in the [LICENSE](LICENSE) file.

---

**Â© 2025-2026 PoisonProof AI Secure Lab. All rights reserved.**
